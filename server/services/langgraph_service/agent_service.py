from models.tool_model import ToolInfoJson
from services.db_service import db_service
from services.message_optimization_service import message_optimization_service
from .StreamProcessor import StreamProcessor
from .agent_manager import AgentManager
from .agent_cache_service import AgentCacheService
import traceback
from utils.http_client import HttpClient
from langgraph_swarm import create_swarm  # type: ignore
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from services.websocket_service import send_to_websocket  # type: ignore
from services.config_service import config_service
from typing import Optional, List, Dict, Any, cast, Set, TypedDict
from models.config_model import ModelInfo
import base64
import os
from routers.templates_router import TEMPLATES
from log import get_logger
import time

logger = get_logger(__name__)

class ContextInfo(TypedDict):
    """Context information passed to tools"""
    canvas_id: str
    session_id: str
    model_info: Dict[str, List[ModelInfo]]


def _fix_chat_history(messages: List[Dict[str, Any]], 
                      template_id: str,
                      template_prompt: Optional[str] = None) -> List[Dict[str, Any]]:
    """ä¿®å¤èŠå¤©å†å²ä¸­ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨

    æ ¹æ®LangGraphæ–‡æ¡£å»ºè®®ï¼Œç§»é™¤æ²¡æœ‰å¯¹åº”ToolMessageçš„tool_calls
    å‚è€ƒ: https://langchain-ai.github.io/langgraph/troubleshooting/errors/INVALID_CHAT_HISTORY/
    """
    fix_start = time.time()
    
    if not messages:
        return messages

    # é¦–å…ˆä½¿ç”¨æ¶ˆæ¯ä¼˜åŒ–æœåŠ¡è¿›è¡Œé¢„å¤„ç†
    logger.info(f"[debug] å¼€å§‹æ¶ˆæ¯å†å²ä¿®å¤ï¼ŒåŸå§‹æ¶ˆæ¯æ•°: {len(messages)}")
    optimized_messages = message_optimization_service.optimize_message_history(messages)
    logger.info(f"[debug] æ¶ˆæ¯ä¼˜åŒ–å®Œæˆï¼Œä¼˜åŒ–åæ¶ˆæ¯æ•°: {len(optimized_messages)}")

    fixed_messages: List[Dict[str, Any]] = []
    tool_call_ids: Set[str] = set()

    # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰ToolMessageçš„tool_call_id
    for msg in optimized_messages:
        if msg.get('role') == 'tool' and msg.get('tool_call_id'):
            tool_call_id = msg.get('tool_call_id')
            if tool_call_id:
                tool_call_ids.add(tool_call_id)

    # ç¬¬äºŒéï¼šä¿®å¤AIMessageä¸­çš„tool_calls
    for msg in optimized_messages:
        if msg.get('role') == 'assistant' and msg.get('tool_calls'):
            # è¿‡æ»¤æ‰æ²¡æœ‰å¯¹åº”ToolMessageçš„tool_calls
            valid_tool_calls: List[Dict[str, Any]] = []
            removed_calls: List[str] = []

            for tool_call in msg.get('tool_calls', []):
                tool_call_id = tool_call.get('id')
                if tool_call_id in tool_call_ids:
                    valid_tool_calls.append(tool_call)
                elif tool_call_id:
                    removed_calls.append(tool_call_id)

            # è®°å½•ä¿®å¤ä¿¡æ¯
            if removed_calls:
                logger.info(f"ğŸ”§ ä¿®å¤æ¶ˆæ¯å†å²ï¼šç§»é™¤äº† {len(removed_calls)} ä¸ªä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨: {removed_calls}")

            # æ›´æ–°æ¶ˆæ¯
            if valid_tool_calls:
                msg_copy = msg.copy()
                msg_copy['tool_calls'] = valid_tool_calls
                fixed_messages.append(msg_copy)
            elif msg.get('content'):  # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„tool_callsä½†æœ‰contentï¼Œä¿ç•™æ¶ˆæ¯
                msg_copy = msg.copy()
                msg_copy.pop('tool_calls', None)  # ç§»é™¤ç©ºçš„tool_calls
                fixed_messages.append(msg_copy)
            # å¦‚æœæ—¢æ²¡æœ‰æœ‰æ•ˆtool_callsä¹Ÿæ²¡æœ‰contentï¼Œè·³è¿‡è¿™æ¡æ¶ˆæ¯
        elif msg.get('role') == 'user' and template_prompt:
            content = msg.get('content', [])
            
            # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„content
            if isinstance(content, str):
                fixed_messages.append({
                    'role': 'user',
                    'content': template_prompt
                })
            # å¤„ç†åˆ—è¡¨æ ¼å¼çš„content
            elif isinstance(content, list):
                new_content: List[Dict[str, Any]] = []
                for content_item in content:
                    if isinstance(content_item, dict) and content_item.get('type') == 'text':
                        content_item['text'] = template_prompt
                        new_content.append(content_item)
                    else:
                        new_content.append(content_item)
                        
                fixed_messages.append({
                    'role': 'user',
                    'content': new_content
                })
            else:
                # å…¶ä»–æ ¼å¼ç›´æ¥ä¿ç•™
                fixed_messages.append(msg)
        else:
            # éassistantæ¶ˆæ¯æˆ–æ²¡æœ‰tool_callsçš„æ¶ˆæ¯ç›´æ¥ä¿ç•™
            fixed_messages.append(msg)
            
    new_messages: List[Dict[str, Any]] = []
    if template_id:
        for msg in fixed_messages:
            if msg.get('role') == 'user':
                try:
                    template = next((t for t in TEMPLATES if t["id"] == int(template_id)), None)
                    if template and template.get("image"):
                        image_path = template["image"]
                        logger.info(f"ğŸ–¼ï¸ æ¨¡æ¿å›¾ç‰‡è·¯å¾„: {image_path}")
                        # æ„å»ºå®Œæ•´è·¯å¾„
                        # image_path æ˜¯ /static/template_images/nizhen.png æ ¼å¼çš„URL
                        # å»æ‰å¼€å¤´çš„ / å¹¶ç›´æ¥ä½¿ç”¨
                        full_image_path = image_path.lstrip('/')
                        logger.info(f"ğŸ“ å®Œæ•´æ–‡ä»¶è·¯å¾„: {full_image_path}")
                        
                        if os.path.exists(full_image_path):
                            with open(full_image_path, "rb") as image_file:
                                image_data = image_file.read()
                                base64_string = base64.b64encode(image_data).decode('utf-8')
                                
                                # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹
                                if image_path.lower().endswith('.png'):
                                    mime_type = 'image/png'
                                elif image_path.lower().endswith('.jpg') or image_path.lower().endswith('.jpeg'):
                                    mime_type = 'image/jpeg'
                                else:
                                    mime_type = 'image/jpeg'  # é»˜è®¤
                                
                                # å¤„ç†contentæ ¼å¼
                                content = msg.get("content", [])
                                if isinstance(content, str):
                                    # å¦‚æœcontentæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
                                    msg["content"] = [
                                        {"type": "text", "text": content},
                                        {
                                            "type": "image_url",
                                            "image_url": {
                                                "url": f'data:{mime_type};base64,{base64_string}'
                                            }
                                        }
                                    ]
                                elif isinstance(content, list):
                                    # å¦‚æœcontentå·²ç»æ˜¯åˆ—è¡¨ï¼Œè¿½åŠ å›¾ç‰‡
                                    content.append({
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f'data:{mime_type};base64,{base64_string}'
                                        }
                                    })
                        else:
                            logger.warn(f"âŒ æ¨¡æ¿å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
                    new_messages.append(msg)
                except Exception as e:
                    logger.error(f"âŒ åŠ è½½æ¨¡æ¿å›¾ç‰‡å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                new_messages.append(msg)
    else:
        new_messages = fixed_messages
    
    logger.info(f"[debug] æ¶ˆæ¯å†å²ä¿®å¤å®Œæˆï¼Œæœ€ç»ˆæ¶ˆæ¯æ•°: {len(new_messages)}, æ€»è€—æ—¶: {(time.time() - fix_start) * 1000:.2f}ms")
    
    # è·å–æ¶ˆæ¯ä¼˜åŒ–æœåŠ¡ç»Ÿè®¡
    msg_stats = message_optimization_service.get_cache_stats()
    logger.info(f"[debug] æ¶ˆæ¯ä¼˜åŒ–ç»Ÿè®¡: {msg_stats}")
    
    return new_messages


async def langgraph_multi_agent(
    messages: List[Dict[str, Any]],
    canvas_id: str,
    session_id: str,
    text_model: ModelInfo,
    tool_list: List[ToolInfoJson],
    system_prompt: Optional[str] = None,
    template_id: str = "",
    template_prompt: Optional[str] = None
) -> None:
    """å¤šæ™ºèƒ½ä½“å¤„ç†å‡½æ•°

    Args:
        messages: æ¶ˆæ¯å†å²
        canvas_id: ç”»å¸ƒID
        session_id: ä¼šè¯ID
        text_model: æ–‡æœ¬æ¨¡å‹é…ç½®
        tool_list: å·¥å…·æ¨¡å‹é…ç½®åˆ—è¡¨ï¼ˆå›¾åƒæˆ–è§†é¢‘æ¨¡å‹ï¼‰
        system_prompt: ç³»ç»Ÿæç¤ºè¯
    """
    try:
        logger.info("[debug] langgraph_multi_agent å¼€å§‹å¤„ç†")
        start_time = time.time()
        
        # 0. ä¿®å¤æ¶ˆæ¯å†å²
        fix_start = time.time()
        fixed_messages = _fix_chat_history(messages, template_id, template_prompt)
        logger.info(f"[debug] æ¶ˆæ¯å†å²ä¿®å¤è€—æ—¶: {(time.time() - fix_start) * 1000:.2f}ms")

        # 1. å°è¯•è·å–ç¼“å­˜çš„agents
        cache_start = time.time()
        cached_result = AgentCacheService.get_cached_agents(
            text_model, tool_list, system_prompt or "", template_prompt or ""
        )
        
        if cached_result:
            agents, agent_names = cached_result
            text_model_instance = AgentCacheService.get_cached_model(text_model)
            if not text_model_instance:
                text_model_instance = _create_text_model(text_model)
                AgentCacheService.cache_model(text_model, text_model_instance)
            logger.info(f"[debug] Agentç¼“å­˜å‘½ä¸­ï¼Œè€—æ—¶: {(time.time() - cache_start) * 1000:.2f}ms")
        else:
            # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œåˆ›å»ºæ–°çš„agents
            model_start = time.time()
            text_model_instance = AgentCacheService.get_cached_model(text_model)
            if not text_model_instance:
                text_model_instance = _create_text_model(text_model)
                AgentCacheService.cache_model(text_model, text_model_instance)
            logger.info(f"[debug] æ–‡æœ¬æ¨¡å‹åˆ›å»ºè€—æ—¶: {(time.time() - model_start) * 1000:.2f}ms")

            # 3. åˆ›å»ºæ™ºèƒ½ä½“
            agent_start = time.time()
            if not template_prompt:
                agents = AgentManager.create_agents(
                    text_model_instance,
                    tool_list,  # ä¼ å…¥æ‰€æœ‰æ³¨å†Œçš„å·¥å…·
                    system_prompt or "",
                    template_prompt or ""
                )
            else:
                agents = AgentManager.create_agents(
                    text_model_instance,
                    tool_list,  # ä¼ å…¥æ‰€æœ‰æ³¨å†Œçš„å·¥å…·
                    system_prompt = """ç›´æ¥è°ƒç”¨ç›¸å…³å·¥å…·""",
                    template_prompt = template_prompt or ""
                )
            
            agent_names = [agent.name for agent in agents]
            logger.info(f"[debug] Agentåˆ›å»ºè€—æ—¶: {(time.time() - agent_start) * 1000:.2f}ms")
            
            # ç¼“å­˜æ–°åˆ›å»ºçš„agents
            AgentCacheService.cache_agents(
                text_model, tool_list, agents, agent_names, system_prompt or "", template_prompt or ""
            )
            logger.info(f"[debug] Agentç¼“å­˜æœªå‘½ä¸­ï¼Œæ€»åˆ›å»ºè€—æ—¶: {(time.time() - cache_start) * 1000:.2f}ms")
        
        logger.info(f'[debug] agent_names: {agent_names}')
        last_agent = AgentManager.get_last_active_agent(
            fixed_messages, agent_names)

        logger.info(f'[debug] last_agent: {last_agent}')

        # 4. åˆ›å»ºæ™ºèƒ½ä½“ç¾¤ç»„
        swarm_start = time.time()
        swarm = create_swarm(
            agents=agents,  # type: ignore
            default_active_agent=last_agent if last_agent else agent_names[0]
        )
        logger.info(f"[debug] Swarmåˆ›å»ºè€—æ—¶: {(time.time() - swarm_start) * 1000:.2f}ms")

        # 5. åˆ›å»ºä¸Šä¸‹æ–‡
        context = {
            'canvas_id': canvas_id,
            'session_id': session_id,
            'tool_list': tool_list,
        }

        logger.info(f"[debug] æ€»åˆå§‹åŒ–è€—æ—¶: {(time.time() - start_time) * 1000:.2f}ms")
        
        # 6. æµå¤„ç†
        stream_start = time.time()
        processor = StreamProcessor(
            session_id, db_service, send_to_websocket)  # type: ignore
        await processor.process_stream(swarm, fixed_messages, context)
        logger.info(f"[debug] æµå¤„ç†è€—æ—¶: {(time.time() - stream_start) * 1000:.2f}ms")
        logger.info(f"[debug] langgraph_multi_agent æ€»è€—æ—¶: {(time.time() - start_time) * 1000:.2f}ms")

    except Exception as e:
        await _handle_error(e, session_id)


def _create_text_model(text_model: ModelInfo) -> Any:
    """åˆ›å»ºè¯­è¨€æ¨¡å‹å®ä¾‹"""
    model = text_model.get('model')
    provider = text_model.get('provider')
    url = text_model.get('url')
    api_key = config_service.app_config.get(  # type: ignore
        provider, {}).get("api_key", "")

    # TODO: Verify if max token is working
    # max_tokens = text_model.get('max_tokens', 8148)

    if provider == 'ollama':
        return ChatOllama(
            model=model,
            base_url=url,
        )
    else:
        # Create httpx client with SSL configuration for ChatOpenAI
        http_client = HttpClient.create_sync_client()
        http_async_client = HttpClient.create_async_client()
        logger.info(f'ğŸ‘‡_create_text_model model {model}')
        return ChatOpenAI(
            model=model,
            api_key=api_key,  # type: ignore
            timeout=300,
            base_url=url,
            temperature=0,
            # max_tokens=max_tokens, # TODO: æš‚æ—¶æ³¨é‡Šæ‰æœ‰é—®é¢˜çš„å‚æ•°
            http_client=http_client,
            http_async_client=http_async_client
        )


async def _handle_error(error: Exception, session_id: str) -> None:
    """å¤„ç†é”™è¯¯"""
    logger.error(f'Error in langgraph_agent {error}')
    tb_str = traceback.format_exc()
    logger.error(f"Full traceback:\n{tb_str}")
    traceback.print_exc()

    await send_to_websocket(session_id, cast(Dict[str, Any], {
        'type': 'error',
        'error': str(error)
    }))
