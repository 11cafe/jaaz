import base64
import aiohttp
import sys
import os
from typing import Any, Optional, Dict
from openai import AsyncOpenAI   

from log import get_logger

logger = get_logger(__name__)

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥ services æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from services.config_service import config_service


class ImageAnalyser:
    """å›¾ç‰‡æ„å›¾ç†è§£åˆ†æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–å›¾ç‰‡åˆ†æå™¨"""
        config = config_service.app_config.get('openai', {})
        self.api_url = str(config.get("url", "")).rstrip("/")
        self.api_token = str(config.get("api_key", ""))

        if not self.api_url:
            raise ValueError("openai API URL is not configured")
        if not self.api_token:
            raise ValueError("openai API token is not configured")

        # ç¡®ä¿ API åœ°å€æ­£ç¡®
        if not self.api_url.endswith('/v1'):
            self.api_url = f"{self.api_url}/v1"

    def _build_headers(self) -> Dict[str, str]:
        """æ„å»ºè¯·æ±‚å¤´"""
        return {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_token}"
        }

    def _encode_image(self, image_path: str) -> str:
        """å°†å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    async def analyze_image_intent(
        self, 
        image_path: str, 
        prompt: str = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒå¤„ç†ä¸“å®¶ï¼Œæ“…é•¿åˆ†æå›¾ç‰‡ï¼Œè§£æå›¾ç‰‡å†…å®¹ï¼Œå¹¶æ ¹æ®ç”¨æˆ·åœ¨å›¾ç‰‡ä¸­çš„æ ‡æ³¨è¿›è¡Œæ„å›¾ç†è§£ï¼Œæœ€ç»ˆç”Ÿæˆä¸€æ®µnana-bananaæ¨¡å‹ä½¿ç”¨çš„å›¾ç‰‡å¤„ç†æç¤ºè¯

# å›¾ç‰‡å¤„ç†çº¦å®š
1. åˆ†æå›¾ç‰‡ä¸­çš„ä¸»ä½“, æ¯”å¦‚è§’è‰²1ï¼Œè§’è‰²2ï¼Œè§’è‰²3ç­‰
2. åˆ†æå›¾ç‰‡ä¸­çš„æ–‡å­—éƒ¨åˆ†ï¼Œæå–æ–‡å­—å†…å®¹,å¹¶è¾“å‡º
3. ç”¨æˆ·éœ€æ±‚çš„æç¤ºè¯ï¼Œåé¢è¦åŠ ä¸€æ®µè¡¥å……è¯´æ˜ï¼Œæœ€ç»ˆåªç”Ÿæˆä¸€å¼ ç»“æœå›¾ï¼Œä¸è¦å¼•ç”¨ä»»ä½•åŸæ–‡å›¾ç‰‡

# è¾“å‡ºçº¦å®š
è¿”å›jsonæ ¼å¼ï¼Œæ¯”å¦‚:
{
  "prompt": "this is ...."
}        
""",
        model: str = "gemini-2.5-pro",
        max_tokens: int = 3000
    ) -> Optional[str]:
        """
        åˆ†æå›¾ç‰‡æ„å›¾

        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯
            model: ä½¿ç”¨çš„æ¨¡å‹
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            Optional[str]: åˆ†æç»“æœæ–‡æœ¬ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            # ç¼–ç å›¾ç‰‡
            base64_image = self._encode_image(image_path)
            
            # æ„å»ºè¯·æ±‚payload
            payload = {
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url", 
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": max_tokens
            }

            # å‘é€è¯·æ±‚
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.api_url}/chat/completions",
                    headers=self._build_headers(),
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=60.0)
                ) as response:
                    if response.status == 200:
                        response_data = await response.json()
                        
                        # æå–æ–‡æœ¬å†…å®¹
                        choices = response_data.get('choices', [])
                        if choices and len(choices) > 0:
                            content = choices[0].get('message', {}).get('content', '')
                            logger.info(f"âœ… Image analysis response data: {content}")
                            return content
                        else:
                            logger.error("âŒ No choices in response")
                            return None
                    else:
                        error_text = await response.text()
                        logger.error(f"âŒ Failed to analyze image: {response.status} - {error_text}")
                        return None

        except Exception as e:
            logger.error(f"âŒ Error analyzing image: {e}")
            return None

    async def analyze_image_base64(
        self,
        system_prompt: str,
        base64_image: str,
        prompt: str = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒå¤„ç†ä¸“å®¶ï¼Œæ“…é•¿åˆ†æå›¾ç‰‡ï¼Œè§£æå›¾ç‰‡å†…å®¹ï¼Œå¹¶æ ¹æ®ç”¨æˆ·åœ¨å›¾ç‰‡ä¸­çš„æ ‡æ³¨è¿›è¡Œæ„å›¾ç†è§£ï¼Œæœ€ç»ˆç”Ÿæˆä¸€æ®µnana-bananaæ¨¡å‹ä½¿ç”¨çš„å›¾ç‰‡å¤„ç†æç¤ºè¯

# å›¾ç‰‡å¤„ç†çº¦å®š
1. åˆ†æå›¾ç‰‡ä¸­çš„ä¸»ä½“, æ¯”å¦‚è§’è‰²1ï¼Œè§’è‰²2ï¼Œè§’è‰²3ç­‰
2. åˆ†æå›¾ç‰‡ä¸­çš„æ–‡å­—éƒ¨åˆ†ï¼Œæå–æ–‡å­—å†…å®¹,å¹¶è¾“å‡º
3. ç”¨æˆ·éœ€æ±‚çš„æç¤ºè¯ï¼Œåé¢è¦åŠ ä¸€æ®µè¡¥å……è¯´æ˜ï¼Œæœ€ç»ˆåªç”Ÿæˆä¸€å¼ ç»“æœå›¾ï¼Œä¸è¦å¼•ç”¨ä»»ä½•åŸæ–‡å›¾ç‰‡

# è¾“å‡ºçº¦å®š
è¿”å›jsonæ ¼å¼ï¼Œæ¯”å¦‚:
{
  "prompt": "this is ...."
}    
""",
        model: str = "gemini-2.5-flash-image", 
        max_tokens: int = 3000
    ) -> Optional[str]:
        """
        åˆ†æbase64ç¼–ç çš„å›¾ç‰‡

        Args:
            base64_image: base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
            prompt: åˆ†ææç¤ºè¯
            model: ä½¿ç”¨çš„æ¨¡å‹
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            Optional[str]: åˆ†æç»“æœæ–‡æœ¬ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            # æ„å»ºè¯·æ±‚payload
            payload = {
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "system",
                                "text": system_prompt
                            },
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": base64_image if base64_image.startswith('data:image/') else f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": max_tokens
            }

            # å‘é€è¯·æ±‚
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.api_url}/chat/completions",
                    headers=self._build_headers(),
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=60.0)
                ) as response:
                    if response.status == 200:
                        response_data = await response.json()  
                        # æå–æ–‡æœ¬å†…å®¹
                        choices = response_data.get('choices', [])
                        if choices and len(choices) > 0:
                            content = choices[0].get('message', {}).get('content', '')
                            logger.info(f"âœ… Image analysis response data: {content}")
                            return content
                        else:
                            logger.error("âŒ No choices in response")
                            return None
                    else:
                        error_text = await response.text()
                        logger.error(f"âŒ Failed to analyze image: {response.status} - {error_text}")
                        return None
        except Exception as e:
            logger.error(f"âŒ Error analyzing image: {e}")
            return None
        
    async def generate_magic_image(
        self,
        images: Dict[str, str],
        prompt: str,
        model: str = "gemini-2.5-flash-image",
        session_id: Optional[str] = None
    ) -> Optional[Dict[str, str]]:
        """
        ç”Ÿæˆé­”æ³•å›¾ç‰‡

        Args:
            prompt: å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
            model: ä½¿ç”¨çš„æ¨¡å‹
            session_id: ä¼šè¯ IDï¼Œç”¨äº WebSocket è¿›åº¦é€šçŸ¥

        Returns:
            Optional[Dict[str, str]]: åŒ…å« base64 æˆ– url çš„å­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            # å‘é€å¼€å§‹ç”Ÿæˆé€šçŸ¥
            if session_id:
                try:
                    from services.websocket_service import send_to_websocket
                    await send_to_websocket(session_id, {
                        'type': 'generation_progress',
                        'status': 'ai_processing',
                        'message': 'ğŸ¤– AI æ­£åœ¨ç”Ÿæˆå›¾åƒ...'
                    })
                except Exception as e:
                    logger.warning(f"âš ï¸ WebSocket é€šçŸ¥å¤±è´¥: {e}")
            
            # åˆ›å»ºå¼‚æ­¥ OpenAI å®¢æˆ·ç«¯
            client = AsyncOpenAI(
                base_url=self.api_url,
                api_key=self.api_token
            )
            
            # æ ¹æ®æ–‡ä»¶æ•°é‡å†³å®šè°ƒç”¨æ–¹å¼
            if images["mask"] == "" and images["image"] != "":
                # åªæœ‰ç›®æ ‡å›¾ç‰‡ï¼Œä¸ä½¿ç”¨æ¨¡æ¿
                logger.info(f"ğŸ“ [DEBUG] ä½¿ç”¨å•å›¾ç‰‡æ¨¡å¼ï¼ˆæ— æ¨¡æ¿ï¼‰")
                # å¼‚æ­¥è¯»å–æ–‡ä»¶
                with open(images["image"], 'rb') as image_file:
                    result = await client.images.edit(
                        model=model,
                        image=image_file,
                        prompt=prompt,
                        response_format="url"
                    )
            else:
                # åŒæ—¶ä½¿ç”¨ç›®æ ‡å›¾ç‰‡å’Œæ¨¡æ¿
                logger.info(f"ğŸ“ [DEBUG] ä½¿ç”¨æ¨¡æ¿æ¨¡å¼")
                logger.info(f"   - ç›®æ ‡å›¾ç‰‡ (image): {images["image"]}")
                logger.info(f"   - æ¨¡æ¿å›¾ç‰‡ (mask): {images["mask"]}")
                logger.info(f"   - æç¤ºè¯ (prompt): {prompt}")
                # å¼‚æ­¥è¯»å–æ–‡ä»¶
                with open(images["image"], 'rb') as image_file, open(images["mask"], 'rb') as mask_file:
                    result = await client.images.edit(
                        model=model,
                        image=image_file,
                        mask=mask_file,
                        prompt=prompt,
                        response_format="url"
                    )

            if result.data and len(result.data) > 0:
                image_data = result.data[0]
                # è¿”å›ç»“æœå­—å…¸
                response_data: Dict[str, str] = {}    
                if hasattr(image_data, 'url') and image_data.url:
                    response_data['result_url'] = image_data.url
                    logger.info(f"âœ… Image generated with URL: {image_data.url}")
                if response_data:
                    return response_data
                else:
                    logger.error("âŒ No image data returned")
                    return None
            else:
                logger.error("âŒ No image data in response")
                return None
        except Exception as e:
            logger.error(f"âŒ Error generating image: {e}")
            return None

if __name__ == "__main__":
    import asyncio
    analyser = ImageAnalyser()
    result = asyncio.run(analyser.analyze_image_intent("/Users/caijunjie/Downloads/ä¸‹è½½.png"))
    print(result)